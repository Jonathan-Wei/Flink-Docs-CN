# 学习Flink：动手训练

### 本次培训的目标和范围

本培训介绍了Apache Flink的简介，其中包括了足以使您开始编写可伸缩的流ETL，分析和事件驱动的应用程序的知识，同时省略了许多（至为重要）细节。重点是为Flink的API提供简单的介绍，以管理状态和时间，并期望他们掌握了这些基础知识，从而可以更好地掌握更详细的参考文档中剩下的知识。每节末尾的链接将带您到更多的地方。

具体来说，您将学习：

* 如何实现流数据处理管道
* Flink如何以及为什么管理状态
* 如何使用事件时间来一致地计算准确的分析
* 如何在连续流上构建事件驱动的应用程序
* Flink如何提供具有精确一次语义的容错，状态流处理

本培训集中于四个关键概念：流数据的连续处理，事件时间，有状态流处理和状态快照。本页面介绍了这些概念。

{% hint style="info" %}
注意：在此培训的基础上，我们进行了一系列动手练习，它们将指导您学习如何使用提出的概念。每节末尾都提供了相关练习的链接。
{% endhint %}

## 流处理

 流是数据的自然栖息地。无论是来自Web服务器的事件，来自证券交易所的交易，还是来自工厂车间机器上的传感器读数，数据都将作为流的一部分创建。但是，当你分析数据时，你可以围绕_有界_ 流或_无界_流来组织处理，并且选择哪种范例会产生深远的影响。

![](../.gitbook/assets/image%20%2847%29.png)

**批处理**是处理有界数据流时的工作模式。在这种操作模式下，你可以选择在产生任何结果之前读取整个数据集，这意味着可以对数据进行排序、计算全局统计信息或生成汇总所有输入的最终报告。

另一方面，**流处理**涉及无限的数据流。至少从概念上讲，输入可能永远不会结束，因此你必须在数据到达时继续进行处理

在Flink中，应用程序由可以由用户定义的**运算符**转换的**流数据流**组成。这些数据流形成有向图，以一个或多个 **源开始**，以一个或多个**接收器**结束。

![](../.gitbook/assets/image%20%2850%29.png)

程序中的转换与数据流中的运算符之间通常存在一一对应的关系。但是，有时，一个转换可能包含多个运算符。

应用程序可能会消耗来自流源（例如消息队列或分布式日志，例如Apache Kafka或Kinesis）的实时数据。但是flink也可以使用来自各种数据源的有限的历史数据。同样，可以将Flink应用程序产生的结果流发送到可以作为接收器连接的各种系统。

![](../.gitbook/assets/image%20%2854%29.png)

### 并行数据流

Flink中的程序本质上是并行的和分布式的。在执行期间，一个 _流_具有一个或多个**流分区**，并且每个_运算符_具有一个或多个**运算符子任务**。操作员子任务彼此独立，并在不同的线程中执行，并且可能在不同的机器或容器上执行。

**运算符子任务**的数量是该特定运算符的**并行**性。同一程序的不同运算符可能具有不同的并行度。

![](../.gitbook/assets/image%20%2853%29.png)

 流可以_按一对一_（或 _转发_）模式或_重新分配_模式在两个运算符之间传输数据：



![](../.gitbook/assets/image%20%2852%29.png)



![](../.gitbook/assets/image%20%2855%29.png)

## 通过状态快照的容错

通过状态快照和流重放的组合，Flink能够提供容错的，一次精确的语义。这些快照捕获分布式管道的整个状态，将偏移记录到输入队列中，并将整个作业图中的状态记录到摄取数据到该点为止。发生故障时，将倒回源，恢复状态，并恢复处理。如上所述，这些状态快照是异步捕获的，而不会妨碍正在进行的处理。

