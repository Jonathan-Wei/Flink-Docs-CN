# 升级应用程序和Flink版本

Flink DataStream程序通常设计为可以长时间运行，例如数周，数月甚至数年。与所有长期运行的服务一样，需要维护Flink流应用程序，包括修复错误，实施改进或将应用程序迁移到更高版本的Flink群集。

本文档介绍了如何更新Flink流应用程序以及如何将正在运行的流应用程序迁移到其他Flink群集。

## 重启流应用程序

 升级流应用程序或将应用程序迁移到其他群集的工作路线基于Flink的[Savepoint](https://ci.apache.org/projects/flink/flink-docs-release-1.10/ops/state/savepoints.html)功能。保存点是在特定时间点的应用程序状态的一致快照。

有两种方法可以从正在运行的流应用程序中获取保存点。

* 获取保存点并继续处理。

```text
> ./bin/flink savepoint <jobID> [pathToSavepoint]
```

建议定期获取保存点，以便能够从上一个时间点重新启动应用程序。

* 采取一个保存点并停止该应用程序为一个动作。

```text
> ./bin/flink cancel -s [pathToSavepoint] <jobID>
```

这意味着在保存点完成后立即取消应用程序，即在保存点之后不执行其他任何检查点。

给定从应用程序中获取的保存点，可以从该保存点启动相同或兼容的应用程序（请参阅下面的“ [应用程序状态兼容性”](https://ci.apache.org/projects/flink/flink-docs-release-1.10/ops/upgrading.html#application-state-compatibility)部分）。从保存点启动应用程序意味着使用保留在保存点中的操作符状态来初始化其操作符的状态。这是通过使用保存点启动应用程序来完成的。

```text
> ./bin/flink run -d -s [pathToSavepoint] ~/application.jar
```

使用获取保存点时原始应用程序（即获取保存点的应用程序）的操作符状态初始化启动的应用程序的操作符。从这一点开始，已启动的应用程序将继续进行处理。

注意： 即使Flink始终恢复应用程序的状态，它也无法将写入恢复到外部系统。如果在不停止应用程序的情况下从保存点恢复，则可能会出现问题。在这种情况下，应用程序可能已在获取保存点后发出了数据。重新启动的应用程序可能会再次发出相同的数据（取决于您是否更改了应用程序逻辑）。取决于`SinkFunction`和存储系统，此行为的确切效果可能会非常不同。如果幂等地写入键值存储（如Cassandra），则两次发出的数据可能是好的，但是如果将持久性日志追加到诸如Kafka的情况下，则有问题。无论如何，应该仔细检查并测试重新启动的应用程序的行为。

## 应用程序状态兼容性

在升级应用程序以修复错误或改进应用程序时，通常的目标是在保留其状态的同时替换正在运行的应用程序的应用程序逻辑。我们通过从原始应用程序获取的保存点启动升级的应用程序来实现。但是，这仅在两个应用程序都_兼容_时才起作用，这意味着升级后的应用程序的操作符可以使用原始应用程序的操作符的状态来初始化其状态。

在本节中，我们讨论如何修改应用程序以保持状态兼容。

### 匹配操作符状态

当应用程序从保存点重新启动时，Flink将保存点中存储的操作符状态与启动应用程序的有状态操作符相匹配。匹配是基于操作符id完成的，操作符id也存储在保存点中。每个操作符都有一个默认ID，该ID派生自应用程序操作符拓扑中的操作符位置。因此，一个未修改的应用程序总是可以从它自己的一个保存点重新启动。但是，如果应用程序被修改，操作符的默认id可能会改变。因此，只有在已显式指定操作符id的情况下，才能从保存点启动已修改的应用程序。为操作符分配id非常简单，可以使用uid\(String\)方法完成，如下所示:

```text
val mappedEvents: DataStream[(Int, Long)] = events
  .map(new MyStatefulMapFunc()).uid("mapper-1")
```

  **注意：**由于存储在存储点中的操作符ID和要启动的应用程序中的操作符ID必须相等，因此强烈建议为将来可能要升级的应用程序的所有操作符分配唯一ID。此建议适用于所有操作符，即具有和未显式声明的操作符状态的操作符，因为某些操作符具有用户不可见的内部状态。在没有分配操作符ID的情况下升级应用程序要困难得多，并且只能通过使用`setUidHash()`方法的低级解决方法来实现。

**重要提示：**从1.3.x版本开始，这也适用于链中的操作符。

默认情况下，保存在保存点中的所有状态必须与启动应用程序的操作符匹配。但是，当从保存点启动应用程序时，用户可以显式地同意跳过\(并因此放弃\)不能与操作符匹配的状态。在保存点中未找到状态的有状态操作符将使用其默认状态进行初始化。用户可以通过调用最佳实践来执行操作，`ExecutionConfig#disableAutoGeneratedUIDs`如果任何操作符不包含自定义唯一ID，该操作都会使作业提交失败。

### 有状态的操作符和用户函数

操作符状态可以是用户定义的或内部的。

* **用户定义的操作符状态：**在具有用户定义的操作符状态的函数中，状态类型由用户明确定义。尽管无法更改操作符状态的数据类型，但是克服此限制的一种解决方法是定义具有不同数据类型的第二个状态，并实施将状态从原始状态迁移到新状态的逻辑。这种方法需要良好的迁移策略，并对[键分区状态](https://ci.apache.org/projects/flink/flink-docs-release-1.10/dev/stream/state/state.html)的行为有深入的了解。
* **内部操作符状态：**诸如窗口或联接操作符之类的操作符拥有内部操作符状态，该状态不会向用户公开。对于这些操作符，内部状态的数据类型取决于操作符的输入或输出类型。因此，更改相应的输入或输出类型会破坏应用程序状态的一致性并阻止升级。下表列出了具有内部状态的操作符，并显示了状态数据类型如何与其输入和输出类型相关。对于应用于密钥流的操作符，密钥类型（KEY）始终也是状态数据类型的一部分。



| 操作符 | 内部操作符状态的数据类型 |
| :--- | :--- |
| ReduceFunction\[IOT\] | IOT \(Input and output type\) \[, KEY\] |
| FoldFunction\[IT, OT\] | OT \(Output type\) \[, KEY\] |
| WindowFunction\[IT, OT, KEY, WINDOW\] | IT \(Input type\), KEY |
| AllWindowFunction\[IT, OT, WINDOW\] | IT \(Input type\) |
| JoinFunction\[IT1, IT2, OT\] | IT1, IT2 \(Type of 1. and 2. input\), KEY |
| CoGroupFunction\[IT1, IT2, OT\] | IT1, IT2 \(Type of 1. and 2. input\), KEY |
| Built-in Aggregations \(sum, min, max, minBy, maxBy\) | Input Type \[, KEY\] |

### 应用拓扑

除了更改一个或多个现有操作符的逻辑之外，还可以通过更改应用程序的拓扑（即通过添加或删除操作符，更改操作符的并行性或修改操作符链接行为）来升级应用程序。

通过更改应用程序的拓扑来升级应用程序时，需要考虑一些事项，以保持应用程序状态的一致性。

* **添加或删除无状态操作符：**除非出现以下情况之一，否则这没有问题。
* **添加有状态操作符：**除非接管另一个操作符的状态，否则将以默认状态初始化。
* **删除有状态的操作符：**除非另一个操作符接管了状态，否则已删除操作符的状态将丢失。启动升级的应用程序时，必须明确同意放弃该状态。
* **更改操作符的输入和输出类型：**在内部状态的操作符之前或之后添加新的操作符时，必须确保不修改有状态操作符的输入或输出类型以保留内部操作符状态的数据类型（有关详情，请参见上文）。
* **更改操作符链接：**可以将操作符链接在一起以提高性能。从1.3.x版本以来的保存点还原时，可以在保持状态一致性的同时修改链。可能会中断链，从而将有状态操作符移出链。也可以将新的或现有的有状态操作符添加或注入到链中，或修改链中的操作符顺序。但是，将保存点升级到1.3.x时，最重要的是拓扑结构在链接方面没有改变。如上面的“ [匹配操作符状态”](https://ci.apache.org/projects/flink/flink-docs-release-1.10/ops/upgrading.html#matching-operator-state)部分所述，应为链中所有操作符分配一个ID 。

## 升级Flink Framework版本

本节介绍了跨版本升级Flink以及在各版本之间迁移作业的一般方法。

简而言之，此过程包括2个基本步骤：

1. 在以前的旧Flink版本中为要迁移的作业获取一个保存点。
2. 在以前的保存点下，在新的Flink版本下恢复作业。

除了这两个基本步骤之外，还可能需要一些其他步骤，具体取决于您要更改Flink版本的方式。在本指南中，我们区分两种跨Flink升级的方法：  **in-place**升级和  **shadow copy** 升级。

对于**in-place**更新，在获取保存点之后，需要：

1. 停止/取消所有正在运行的作业。
2. 关闭运行旧版Flink的群集。
3. 将Flink升级到群集上的较新版本。
4. 在新版本下重新启动集群。

对于**shadow copy**，需要：

1. 从保存点恢复之前，除了旧的Flink安装外，还要安装新的Flink版本的新安装。
2. 使用新的Flink安装程序从保存点恢复。
3. 如果一切正常，请停止并关闭旧的Flink群集。

在下文中，我们将首先介绍成功完成工作迁移的前提条件，然后再详细介绍之前概述的步骤。

### 前提条件

 开始迁移之前，请检查要迁移的作业是否遵循[保存点](https://ci.apache.org/projects/flink/flink-docs-release-1.10/ops/state/savepoints.html)的最佳做法。另外，请查看《 [API迁移指南》，](https://ci.apache.org/projects/flink/flink-docs-release-1.10/dev/migration.html)以查看是否有任何与将保存点迁移到较新版本有关的API更改。

特别建议你检查作业中是否为操作符设置的显式uid。

这是一个软先决条件，如果忘记分配uid，恢复应该仍然可以工作。如果遇到不生效的情况，则可以使用setUidHash\(String hash\)手动调用将以前的Flink版本中生成的遗留顶点id添加到作业中。对于每个操作符\(在操作符链中:只有head操作符\)，必须分配32个字符的十六进制字符串，表示可以在web ui或操作符日志中看到的哈希值。

 除了操作符uid之外，当前还有两个_很难_进行的作业迁移前提条件，这些条件会使迁移失败：

1. 我们不支持在RocksDB中使用`semi-asynchronous`模式检查点的状态迁移。如果旧作业使用这种模式，仍然可以在使用作为迁移基础的保存点之前将作业更改为使用`fully-asynchronous`模式。
2.  另一个**重要的**前提条件是，必须从同一位置（绝对）路径下的新安装访问所有保存点数据。这还包括对从保存点文件内部引用的任何其他文件（状态后端快照的输出）的访问，包括但不限于通过[State Processor API](https://ci.apache.org/projects/flink/flink-docs-release-1.10/dev/libs/state_processor_api.html)修改而获得的其他引用的保存点。当前，任何保存点数据都由元数据文件内的绝对路径引用，因此无法通过典型的文件系统操作来重定位保存点。

### 步骤1：在旧的Flink版本中获取一个保存点。

作业迁移的第一步是在旧版Flink中保存作业的保存点。可以使用以下命令执行此操作：

```text
$ bin/flink savepoint :jobId [:targetDirectory]
```

有关更多详细信息，请阅读[保存点文档](https://ci.apache.org/projects/flink/flink-docs-release-1.10/ops/state/savepoints.html)。

### 步骤2：将集群升级为新的Flink版本

在此步骤中，我们将更新集群的框架版本。这基本上意味着用新版本替换Flink安装的内容。此步骤取决于你如何在集群中运行Flink（例如，独立运行，在Mesos上运行，等等）。

如果您不熟悉在群集中安装Flink的信息，请阅读[部署和群集设置文档](https://ci.apache.org/projects/flink/flink-docs-release-1.10/ops/deployment/cluster_setup.html)。

### 步骤3：从保存点以新的Flink版本恢复作业

作为作业迁移的最后一步，你将在新的集群上采用的保存点恢复。可以使用以下命令执行此操作：

```text
$ bin/flink run -s :savepointPath [:runArgs]
```

同样，有关更多详细信息，请参阅[保存点文档](https://ci.apache.org/projects/flink/flink-docs-release-1.10/ops/state/savepoints.html)。  


## 兼容性表格

| 创建于\还原于 | 1.1.x | 1.2.x | 1.3.x | 1.4.x | 1.5.x | 1.6.x | 1.7.x | 1.8.x | 1.9.x | 1.10.x | 局限性 |
| :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- |
| **1.1.x** | Ø | Ø | Ø |  |  |  |  |  |  |  | 从Flink 1.1.x迁移到1.2.x +的作业的最大并行度目前固定为该作业的并行度。这意味着迁移后不能增加并行度。此限制可能会在将来的错误修正版本中删除。 |
| **1.2.x** |  | Ø | Ø | Ø | Ø | Ø | Ø | Ø | Ø | Ø | 从Flink 1.2.x迁移到Flink 1.3.x +时，不支持同时更改并行性。在迁移到Flink 1.3.x +之后，用户必须首先获取一个保存点，然后更改并行性。  为CEP应用程序创建的保存点无法在1.4.x +中还原。  Flink 1.2中包含Scala TraversableSerializer的保存点不再与Flink 1.8兼容，因为该序列化程序已进行了更新。通过首先升级到Flink 1.3和Flink 1.7之间的版本，然后再更新到Flink 1.8，可以解决此限制。 |
| **1.3.x** |  |  | Ø | Ø | Ø | Ø | Ø | Ø | Ø | Ø | 如果保存点包含Scala案例类，则从Flink 1.3.0迁移到Flink 1.4。\[0,1\]将失败。用户必须直接迁移到1.4.2+。 |
| **1.4.x** |  |  |  | Ø | Ø | Ø | Ø | Ø | Ø | Ø |  |
| **1.5.x** |  |  |  |  | Ø | Ø | Ø | Ø | Ø | Ø | 在版本1.6.x到1.6.2以及1.7.0中使用1.5.x创建的广播状态恢复时存在一个已知问题：[FLINK-11087](https://issues.apache.org/jira/browse/FLINK-11087)。升级到1.6.x或1.7.x系列的用户需要分别直接迁移到高于1.6.2和1.7.0的次要版本。 |
| **1.6.x** |  |  |  |  |  | Ø | Ø | Ø | Ø | Ø |  |
| **1.7.x** |  |  |  |  |  |  | Ø | Ø | Ø | Ø |  |
| **1.8.x** |  |  |  |  |  |  |  | Ø | Ø | Ø |  |
| **1.9.x** |  |  |  |  |  |  |  |  | Ø | Ø |  |
| **1.10.x** |  |  |  |  |  |  |  |  |  | Ø |  |

